V Hello there! My name is Alexander Held, and I recently joined the AMVA4NewPhysics network as an Early Stage Researcher (ESR), who will be based mostly at CERN in Geneva. Before we get to any details regarding my work here in the following two years, I am going to take this opportunity to briefly introduce myself. Me in front of the ATLAS detector (you can only see a small part of it in the background, the full detector is huge!) I was born and raised in Germany. My first proper particle physics experience was a two-week internship at CERN during my time in high school, where I was working on silicon detector calibration. This was right around when the Large Hadron Collider was starting to deliver proton beams at 7 TeV, and I distinctively remember that there seemed to be an aura of excitement everywhere. Physicists were of course hoping to see signs of a Higgs boson (thought it took some more time for that to really happen), but were also curious as to what other unexpected phenomena might maybe appear. In my time as an undergraduate, I wanted to give some other fields of physics a try. An internship at the Max Planck Institute for Radio Astronomy in Bonn showed me how much I enjoy working on large scale data analysis. I analysed telescope data of star-forming regions, with the goal to better understand the physical conditions in these clouds. In order to extract parameters like temperature and composition, I automated a fitting procedure of spectral line data. For my undergraduate thesis, I worked on a topic in theoretical quantum mechanics. Compared to some of these other fields of physics, the description of particle physics actually seemed less elegant and more convoluted to me. This was great motivation for me to learn more about it! Two years ago I started in the graduate physics program at the University of British Columbia in Vancouver, where I am now a Ph.D. candidate. I am a member of the ATLAS collaboration, and in my research I analyse data from this detector to search for collisions involving Higgs bosons and top quarks (a process also called ttH). Specifically, I am focusing on the Matrix Element Method (MEM), which Alessia has already briefly described here. I am going to describe my research in more detail at some point in the future, but for now only a very brief motivation for my work: even though there was already the 2013 nobel prize awarded to François Englert and Peter W. Higgs for their prediction of the Higgs mechanism, this does not mean that we have already confirmed all predictions experimentally. Most notably, there are four major ways of producing Higgs bosons. The ATLAS and CMS collaborations are examining all these different production mechanisms, but some, like the ttH process, are very rare and tricky to measure. We thus have no conclusive measurements of this process yet. Such measurements could either confirm yet another aspect of the predictions by the Standard Model of particle physics, or give us clues of new physics phenomena. I am involved in the analysis of ATLAS data in order to see which case it will be. So how did I end up in the AMVA4NewPhysics network? While spending some time at CERN earlier this summer, I found out that there was a posting looking for an ESR to work on MEM in ttH. I had been working on exactly that topic for two years already, and the position would have allowed me to continue doing research towards my Ph.D., while simultaneously offering additional benefits. I applied and was accepted! Living in Vancouver was great (I highly recommend a visit if you have the chance!), but for now I am back in Europe. One thing I will certainly not miss is attending video conference meetings at four in the morning (they typically take place in Geneva, and the nine-hour time difference to the North American west coast is not exactly convenient). Now I can attend these meetings in person at much more pleasant times of the day. I am looking forward to the upcoming two years in the network and working together with the other members to achieve our common goals. You can stay up to date with our progress by following this blog. Talk to you soon! Last month, I had the pleasure to attend the 2017 edition of the European School of High-Energy Physics in Évora, Portugal. We were about 100 students, including my fellow ESR Pablo. The two week program included lectures on many high-energy physics-related topics, such as the Standard Model, cosmology, statistics, Higgs physics, and phenomena beyond the Standard Model. In the evenings, after the lectures, the program foresaw discussion sessions in smaller groups. These sessions were a great way to go over the content of the lectures again, clarify concepts, and answer questions. ESHEP2017 group picture Besides the physics content, the school also included a segment aimed at outreach. Each discussion group, comprised of about 15 students, had to prepare an eight minute talk on a particle physics topic. These talks were meant to be understandable by the general public. To help us with this, we had the chance to see a professional doing outreach in person: CERN Director General, Fabiola Gianotti, gave a public talk in Évora, followed by a panel discussion. The talk was recorded, you can find it here if you are interested. Further training was provided by a pair of former BBC journalists. This included a few exercises; especially helpful to me was a simulated one-on-one radio interview about a fictitious physics discovery. Those interviews were recorded, too, so we had the chance to listen back to them again later and analyse our behaviour. At this point you might wonder why the title of this blog post is about grandmas. This brings us back to the outreach projects, where my group was given the Higgs boson as a topic. Every good talk about the Higgs should contain some attempt at explaining the Higgs mechanism [1]. This mechanism describes how fundamental particles acquire mass, and it is a tricky beast to explain properly without reverting back to lots of algebra. Typically, analogies are used to give an idea as to how this mechanism works. A famous example is the analogy of a cocktail party by David J. Miller. I personally like this explanation from The New York Times a lot, which includes nice visualizations and contains a bit more than just an analogy. My group after presenting our Higgs boson outreach talk We wanted to come up with a new analogy, and this is where grandmas come in. Imagine a grandmother who hands out homemade cookies to people passing by. She likes her grandchildren a lot, so she gives out more cookies to them than to other people. Now imagine not only one grandmother, but many grandmothers, everywhere in the universe: this is a field of grandmothers. People passing by these grandmothers will receive cookies, they interact with the grandmother field. By interacting with the field, these people will acquire mass. The grandchildren have a stronger interaction with the field than the rest of the people (since they obtain more cookies!), so they consequently acquire more mass. In order to translate this back into physics terms, just replace the grandmother field by a Higgs field, and replace the people interacting with the field by fundamental particles. The interaction strength of the various fundamental particles with the Higgs field varies, thus they have different masses. Our presentation at the school was recorded, you can find John explaining the mechanism in this video (650 MB file). As it usually is the case with analogies, our grandma version has its shortcomings. I want to point out one important point: From the explanation above, you could imagine that particles acquire more and more mass while travelling through the Higgs field, since they keep on collecting cookies in our analogy. This is not the case! The particle masses are determined by an interaction strength, which we describe as the amount of cookies exchanged. The masses do not correspond to the total amount of cookies collected over time. After attending the school, I explored Portugal a bit, this picture was taken somewhere along the West Coast. I want to conclude with a recommendation: Try out Queijadas if you are in Portugal! They are a delicious, sweet pastry, which I was able to find in both Évora and Sintra. [1] The mechanism goes by many names, and is often times also called Brout\u2013Englert\u2013Higgs mechanism. I do not intend to discredit any of the theorists instrumental to its prediction, but call it Higgs mechanism for brevity. The winter conferences are approaching, where both ATLAS and CMS are aiming to show their latest scientific results with the data gathered in the last year. 2016 saw a huge increase in the size of this dataset, which results in a drastic increase in sensitivity to some of the phenomena we are searching for. A large amount of work goes into understanding this data and ensuring that the models we are comparing it to are accurate. In this post, I am going to describe just one aspect of this process, which I am currently involved in. We are colliding an enormous amount of protons at the LHC. The frequency with which protons collide when the accelerator is running is far too large to feasibly process and store all information about every single collision. Luckily, there is a trigger system in place, which identifies \u201cinteresting\u201d collisions and saves the relevant information for just those. The majority of collisions will be ignored, the triggers will not fire and the information about those collisions will be lost. This is not a big problem, since the physics phenomena that typically take place in these collisions are well understood already. \u201cInteresting\u201d collisions When do these triggers fire? What is an \u201cinteresting\u201d collision? For example, the triggers look for electrons and muons, for objects with very high energy, or for collision events where momentum was seemingly not conserved. The last example occurs when neutrinos are present, since they leave the detectors without a trace. A large amount of seemingly missing momentum could also be a sign of dark matter and other exotic particles. I am currently involved in deriving corrections for the muon trigger in our simulations at ATLAS. This muon trigger system aims to detect when a collision produced muons. It is not perfect, and will consequently miss some fraction of muons. We can quantify this effect by deriving an efficiency for the trigger. As an example, an efficiency of 90% indicates that on average the trigger will correctly identify 9 out of 10 events that contained a muon. We then compare the efficiency in data to the efficiency in our simulations. If the efficiencies do not agree, we can use this knowledge to correct our simulation. You may wonder where a discrepancy could come from. For example, certain detector parts may not function correctly while we are collecting data. Imagine a muon being produced in a collision, and then passing through a detector element that was shut off due to a technical problem \u2013 we have no chance of identifying this muon, and the muon trigger will not fire! In this case, the trigger efficiency for data (real collisions) will be lower than the efficiency for simulated collisions (where we did not take all possible detector defects into account). My task is measuring and comparing trigger efficiencies for data and simulation. In a second step, I then derive corrections, which are applied to the muon trigger simulation. These corrections resolve potential discrepancies between data and simulation . Measuring the trigger efficiencies in data and in simulation may sound fairly straightforward, but there is a catch. We can count how many times the muon trigger fired in our data collision events, but how do we keep track of the amount of times when it did not fire, despite there being a muon which it should have identified? The method A solution to this problem is known as the \u201ctag and probe method\u201d. We select a second trigger, which we call our \u201ctag\u201d trigger. This trigger should fire based on some property unrelated to the muon [1] . Our muon trigger becomes the \u201cprobe\u201d trigger. The procedure then looks like this: Count the amount of collisions for which the tag trigger fired and where there was also a muon produced [2] : call this amount T Count the amount of collisions where the tag trigger fired, there was a muon produced and the probe trigger also fired: call this amount P The probe trigger efficiency is P/T. Apply this procedure for both data and simulation, compare the efficiencies and derive a correction if required. To round things off, here is an example of how this works in practice: You can apply the procedure to measure the muon trigger efficiencies in top quark pair production, where the decay products include a muon and a neutrino from a W boson (which itself is a decay product from a top quark). As I mentioned earlier, we can identify such events with a trigger looking for seemingly non-conserved transverse momentum, this will be our tag trigger. We then use a muon trigger as our probe trigger, and finally can calculate the muon trigger efficiencies we are interested in. Tag and probe in action Here is a plot showing the method in action with data collected in 2012 [3]: Ignore everything in green and blue for now, and focus on the top part of the plot first. You can see the muon trigger efficiency in data and simulation (\u201cMC\u201d) as a function of the transverse muon momentum (\u201cMuon pT\u201c). The trigger is roughly 71% efficient in data (shown as triangles with red error bars), and also around 71% efficient in the simulation, shown as red hashed areas. The efficiency does not strongly depend on the muon transverse momentum (the distribution is rather flat). The bottom part of the plot shows the ratio of data and simulation efficiencies, which you can interpret as a correction factor that should be applied to the simulation. In this case, no large correction is required (a correction factor of 1 is equal to no correction). The results shown in blue on this plot are also obtained using tag and probe, this time targeting muons that originate from a different process: W bosons produced in association with jets. The red results are obtained with top quark pairs, as I described earlier. Finally, the correction factor shown in green is derived from yet another process (Z boson production). As you can see, the correction factors from these three different processes are in good agreement within their respective uncertainties. [1] This aspect is important; if the tag trigger shows correlation with the muon trigger, it will bias the conclusions. [2] If any trigger fired for a collision event (and it is thus saved), we then proceed to take a much closer look at it.  It is possible that the muon trigger missed a muon in an event, but we find the muon anyway when taking this closer look. [3] Eur. Phys. J. C (2015) 75:120, https://arxiv.org/abs/1408.3179
p1
.