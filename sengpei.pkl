V The AMVA4NewPhysics work package I am involved in is related to developing tools for recasting new physics searches, with a particular focus on multivariate analyses. I would like to explain a little more about it in this article. Let me begin by describing the motivation to look for new physics at the Large Hadron Collider (LHC). Despite the fact that the Standard Model (SM) of particle physics is very successful at describing most properties of elementary particles, there are many reasons to believe that nature is much more complicated and there is new physics, or physics beyond the Standard Model (BSM). Firstly, there is the hierarchy problem that asks why the electroweak scale or the Higgs mass, 125 GeV can be so light compared to the cutoff scale of the SM, the Planck scale if there is no BSM physics, which is 17 orders of magnitude larger than the electroweak scale. The Higgs mass is unprotected by any symmetry in the SM, and the quantum corrections to its mass are proportional to the cutoff scale. One requires an extreme fine tuning to keep the Higgs boson light while renormalizing the quantum effects, which seems to be totally unnatural. Secondly, as explained previously, there exists dark matter, which is thought by many to be a new type of elementary particle. For these and many other motivations, people are excited at the prospects of discovering BSM physics at the LHC.   Supersymmetric production of neutralinos by squark decays in a proton-proton interaction How do experimentalists analyze the LHC data? In a typical ATLAS or CMS analysis, for example the search for squarks (supersymmetric partner of SM quarks) by the ATLAS collaboration, one does not really \u201csee\u201d the squarks at the LHC, but the decay products of them. In the example above, experimentalists limit themselves to events where there are jets and a large transverse energy (originated from neutralino, a type of supersymmetric particle invisible to the detector) in the final state. Then, analyses are performed to determine whether the observed events are originated from known SM physics (background), or from some new physics (signal). The result of these analyses is interpreted in terms of statistical limit/constraint on the parameter of the model (squark mass in this example). Typically, experimentalists utilize two approaches to interpret the LHC data. The first approach is investigating a limited number of parameters by considering a constrained version of the full model. For example, one can consider the experimental constraints on the constrained Minimal Supersymmetric Standard Model (CMSSM) which contains 5 free parameters (in contrast with the full Minimal Supersymmetric Standard Model, which has more than 100 free parameters!). However, the interpretation often becomes difficult when one (especially theorist with new ideas or models) wishes to consider even a slightly modified version of the model. Therefore, this approach only allows a limited class of models to be tested. The second approach employed is the so-called simplified model approach, where only a small number of particles and interactions are considered while interpreting the LHC data. Limits are often presented by assuming a certain production and decay topology of particles. For example, limits can be placed on squarks assuming squarks are pair-produced via QCD interaction and decay with 100% branching ratio to quark and a neutralino (see figure). This approach aims to impose experimental constraints on a wide class of models. The shortcoming of this approach is that most realistic models have more complicated interactions that are not covered by the simplified models. Using this result may lead to an inappropriate evaluation of the realistic model of interest. The aim of recasting LHC analyses is to avoid the shortcomings mentioned above and study the experimental limits of models not covered by the experimentalists. To do this, experimental analyses have to be implemented by generating events, simulating detector effects and performing statistical analyses. By doing so, one can study how a certain LHC analysis constrains in principle any model of interest. Furthermore, as any model of new physics will generically have multiple distinctive predictions of collider signatures which have to be cross-checked when contemplating the validity of the model, recasting also allows one to do this kind of checks flexibly. You can find some of my previous works which more or less follow this philosophy here, here, and here. Within this network, I am particularly interested in recasting multivariate analyses at the LHC. That is all for this article. Let me know your thoughts in the comment section! Hello there! My name is Seng Pei Liew, and I am the \u201cMarie Sklodowska-Curie Actions\u201d Innovative Training Network (AMVA4NewPhysics) early-stage researcher based at the Technische Universitat Munich (TUM). I am tasked in the network to look for new physics at the Large Hadron Collider (LHC) using advanced statistical tools. In my very first article here, I would like to talk more about myself and my research interests. I have spent my graduate years at the University of Tokyo (Japan), doing research in theoretical particle physics. My research interest is, in a broad sense, in probing beyond the Standard Model (BSM) physics by making connection between theory and experimental observations. I have been mainly involved in studying phenomenology aspects of dark matter and physics related to the LHC. Let me make a very brief introduction to these topics. It is well accepted within the scientific community that a portion of matter in our universe is \u201cdark\u201d. Dark matter has gravitational interaction but, at least at the large scale (celestial scale), it has almost negligible non-gravitational (electroweak, strong) interaction with ordinary matter. Cosmological and astrophysical observations indicate that dark matter is most likely to be particle-like. However, its property as a particle is not well clarified. That weakly interacting massive particles (WIMPs) constitute dark matter is a very popular postulate, because the correct (thermally produced) abundance of dark matter can be obtained via the WIMP paradigm. If it is true, dark matter can interact with Standard Model (SM) particles and between itself. Then, we expect at least three kinds of dark matter discovery channels: direct, indirect dark matter detection, and dark matter production at collider (see figure below). The latter is probably the most exciting one as we have the LHC churning out various results currently. Along with the recent advances in machine learning (particularly deep learning), it is timely to studying advanced statistical tools which may turn out to be useful for studying LHC physics. Three ways to study dark matter (DM): dark matter particles interact with ordinary matter (SM, for standard model particles) by three different main processes. The rightward-pointing arrow at the bottom indicates annihilation of two DM bodies into pairs of SM particles (indirect detection), which we can study by looking for cosmic radiation from dense regions of the cosmos; the upward-pointing arrow indicates how we can detect the scattering of a DM particle with a SM one in a \u201cpassive\u201d detector, where atoms are carefully looked at for signals of this bouncing effect (direct detection). The third arrow on the top, pointing leftward, indicates how we can create pairs of DM particles by colliding ordinary matter (collider search), e.g. at the LHC. That is all for this post. I hope to write more about dark matter, LHC, and machine learning in the upcoming posts. Recently we have witnessed the birth of gravitational-wave astronomy, as gravitational waves were directly observed for the first time. Subsequently, gravitational waves due to binary neutron star merger were detected along with associated electromagnetic events, opening a new era of multi-messenger astronomy. The field of high energy physics has arguably seen little progress in comparison. Indeed, the final piece of the Standard Model (SM), the Higgs boson, has been discovered in 2012. There is, however, no other trace of new particles at the LHC, which is promised by many theories arguing that the Higgs mass is \u201cnatural\u201d. This drives beyond-the-SM (BSM) enthusiasts like me to near depression. That no new particle has been discovered (so far) may imply that we are looking in the wrong direction for probing new physics. Instead of searching for new particles directly, alternate approaches are cried out for. Indeed, when life gives us the Higgs, we should figure out ways to search for BSM physics using the Higgs. One way of finding traces of new particles is by making measurements of the Higgs couplings. This is because the Higgs couplings could be significantly affected by the existence of new particles/physics. In fact, it is almost guaranteed that the \u201cnaturalness\u201d problem mentioned above could be illuminated by measuring the Higgs couplings. Since there is no sign of new physics, it is likely that there is a gap in energy scale between the SM and new physics. The presence of BSM, however, can then be parametrized with a set of higher dimensional operators, even without knowing the details of the BSM model. Of particular interest are those related to gluon fusion, the main mechanism of Higgs production at the LHC (taken from here): One way (which is of particular interest to this network) of studying these operators is via Higgs pair production at the LHC. The figure below (taken from here) shows Feynman diagrams of double Higgs production in the SM, as well as those induced by the effective operators. Work Packages 1 (focusing on Higgs pair production) and 2 (focusing on new physics searches) of this network are particularly relevant to this research direction. Last but not least, LHC Higgs measurement emerges also as an unprecedented opportunity for applying novel multivariate techniques to analyzing data. The results from the LHC are not very encouraging so far. The current situation mirrors the pre-LHC era: there was no direct evidence of \u201cnew\u201d physics, i.e. the Higgs, at the Large Electron Positron Collider (LEP) or Tevatron (the top quark was discovered nevertheless) during the 90s However, electroweak measurements had been able to constrain the mass of the Higgs boson indirectly to less than 161 GeV. Perhaps we will encounter such a situation again, where no new particles can be found and Higgs measurements will play an important role, but let us wait and see what future runs of the LHC tell us.
p1
.